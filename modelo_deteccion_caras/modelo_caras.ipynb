{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Aitor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#OpenCV module\n",
    "import cv2\n",
    "#Modulo para leer directorios y rutas de archivos\n",
    "import os\n",
    "#OpenCV trabaja con arreglos de numpy\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "captura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV module\n",
    "import cv2\n",
    "#Modulo para leer directorios y rutas de archivos\n",
    "import os\n",
    "#OpenCV trabaja con arreglos de numpy\n",
    "import numpy\n",
    "#Obtener el nombre de la persona que estamos capturando\n",
    "import sys\n",
    "nombre = 'antonio'\n",
    "\n",
    "#Directorio donde se encuentra la carpeta con el nombre de la persona\n",
    "dir_faces = './caras/'\n",
    "path = os.path.join(dir_faces, nombre)\n",
    "\n",
    "#Tamaño para reducir a miniaturas las fotografias\n",
    "size = 4\n",
    "\n",
    "#Si no hay una carpeta con el nombre ingresado entonces se crea\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "#cargamos la plantilla e inicializamos la webcam\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "img_width, img_height = 112, 92\n",
    "\n",
    "#Ciclo para tomar fotografias\n",
    "count = 0\n",
    "while count < 100:\n",
    "    #leemos un frame y lo guardamos\n",
    "    rval, img = cap.read()\n",
    "    img = cv2.flip(img, 1, 0)\n",
    "\n",
    "    #convertimos la imagen a blanco y negro\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #redimensionar la imagen\n",
    "    mini = cv2.resize(gray, (int(gray.shape[1] / size), int(gray.shape[0] / size)))\n",
    "\n",
    "    \"\"\"buscamos las coordenadas de los rostros (si los hay) y\n",
    "   guardamos su posicion\"\"\"\n",
    "    faces = face_cascade.detectMultiScale(mini)    \n",
    "    faces = sorted(faces, key=lambda x: x[3])\n",
    "    \n",
    "    if faces:\n",
    "        face_i = faces[0]\n",
    "        (x, y, w, h) = [v * size for v in face_i]\n",
    "        face = gray[y:y + h, x:x + w]\n",
    "        face_resize = cv2.resize(face, (img_width, img_height))\n",
    "        \n",
    "        #Dibujamos un rectangulo en las coordenadas del rostro\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        #Ponemos el nombre en el rectagulo\n",
    "        cv2.putText(img, nombre, (x - 10, y - 10), cv2.FONT_HERSHEY_PLAIN,1,(0, 255, 0))        \n",
    "\n",
    "        #El nombre de cada foto es el numero del ciclo\n",
    "        #Obtenemos el nombre de la foto\n",
    "        #Despues de la ultima sumamos 1 para continuar con los demas nombres\n",
    "        # Filtrar solo nombres numéricos y convertirlos a enteros\n",
    "        numeros = [int(n.split('.')[0]) for n in os.listdir(path) if n.split('.')[0].isdigit()]\n",
    "\n",
    "        # Si la lista está vacía, empezar desde 1; de lo contrario, obtener el siguiente número\n",
    "        pin = max(numeros, default=0) + 1\n",
    "\n",
    "        #Metemos la foto en el directorio\n",
    "        print\n",
    "        cv2.imwrite('%s/%s.png' % (path, pin), face_resize)\n",
    "\n",
    "        #Contador del ciclo\n",
    "        count += 1\n",
    "\n",
    "    #Mostramos la imagen\n",
    "    cv2.imshow('OpenCV Entrenamiento de '+nombre, img)\n",
    "\n",
    "    #Si se presiona la tecla ESC se cierra el programa\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formando...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Parte 1: Creando el entrenamiento del modelo\n",
    "print('Formando...')\n",
    "\n",
    "# Directorio donde se encuentran las carpetas con las caras de entrenamiento\n",
    "dir_faces = './caras/'\n",
    "\n",
    "# Tamaño para reducir a miniaturas las fotografías\n",
    "size = 4\n",
    "\n",
    "# Crear una lista de imágenes y una lista de nombres correspondientes\n",
    "(images, labels, names, id) = ([], [], {}, 0)\n",
    "for (subdirs, dirs, files) in os.walk(dir_faces):\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir\n",
    "        subjectpath = os.path.join(dir_faces, subdir)\n",
    "        for filename in os.listdir(subjectpath):\n",
    "            path = os.path.join(subjectpath, filename)\n",
    "            label = id\n",
    "            img = cv2.imread(path, 0)\n",
    "            img = cv2.resize(img, (112, 92))\n",
    "            images.append(img.flatten())  # Convertimos la imagen en un vector\n",
    "            labels.append(int(label))\n",
    "        id += 1\n",
    "\n",
    "(im_width, im_height) = (112, 92)\n",
    "\n",
    "# Convertir a arrays de numpy\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "def compare_faces(face_vector, images, labels, names):\n",
    "    similarities = cosine_similarity([face_vector], images)\n",
    "    best_match_idx = np.argmax(similarities)\n",
    "    best_match_score = similarities[0][best_match_idx]\n",
    "    \n",
    "    if best_match_score > 0.99:  # Umbral de similitud\n",
    "        return names[labels[best_match_idx]], best_match_score\n",
    "    else:\n",
    "        return \"Desconocido\", best_match_score\n",
    "\n",
    "# Parte 2: Utilizar el modelo entrenado en funcionamiento con la cámara\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Leemos un frame y lo guardamos\n",
    "    rval, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1, 0)\n",
    "\n",
    "    # Convertimos la imagen a blanco y negro    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Redimensionar la imagen\n",
    "    mini = cv2.resize(gray, (int(gray.shape[1] / size), int(gray.shape[0] / size)))\n",
    "\n",
    "    # Buscamos las coordenadas de los rostros (si los hay) y guardamos su posición\n",
    "    faces = face_cascade.detectMultiScale(mini)\n",
    "    \n",
    "    for i in range(len(faces)):\n",
    "        face_i = faces[i]\n",
    "        (x, y, w, h) = [v * size for v in face_i]\n",
    "        face = gray[y:y + h, x:x + w]\n",
    "        face_resize = cv2.resize(face, (im_width, im_height))\n",
    "        face_vector = face_resize.flatten()  # Convertir la imagen en un vector\n",
    "\n",
    "        # Comparar con las caras de entrenamiento\n",
    "        cara, score = compare_faces(face_vector, images, labels, names)\n",
    "        \n",
    "        # Dibujar rectángulo y mostrar nombre\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        cv2.putText(frame, f'{cara} - {score:.2f}', (x - 10, y - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0))\n",
    "        \n",
    "    cv2.imshow('OpenCV Reconocimiento facial', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any\n",
    "from mlserver import MLModel\n",
    "from mlserver.types import InferenceRequest, InferenceResponse, ResponseOutput\n",
    "from mlserver.errors import InferenceError\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Import the detector class\n",
    "from yolo_detector import YOLOObjectDetector\n",
    "\n",
    "\n",
    "class ObjectDetectionModel(MLModel):\n",
    "    \n",
    "    async def load(self) -> bool:\n",
    "        # Create the detector instance directly\n",
    "        self.model = YOLOObjectDetector()\n",
    "        self.model2 = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "        # No need to load it now - will load on first prediction\n",
    "        self.ready = True\n",
    "        return self.ready\n",
    "\n",
    "    async def predict_caras(self, frame, boundingBox) -> bool:\n",
    "        \n",
    "        # Get predictions\n",
    "        x, y, w, h = boundingBox\n",
    "        mini = frame[y:y + h, x:x + w]\n",
    "        predictions = self.model2.detectMultiScale(mini)\n",
    "\n",
    "        face_i = predictions[0]\n",
    "        (x2, y2, w2, h2) = [v * size for v in face_i]\n",
    "        face = frame[y2:y2 + h2, x2:x2 + w2]\n",
    "        face_resize = cv2.resize(face, (112, 92))\n",
    "        face_vector = face_resize.flatten()  # Convertir la imagen en un vector\n",
    "        \n",
    "        return face_vector\n",
    "\n",
    "    async def predict(self, payload: InferenceRequest) -> InferenceResponse:\n",
    "        try:\n",
    "            # Extract images from payload\n",
    "            inputs = payload.inputs[0]\n",
    "            image_data = inputs.data\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = self.model2.detectMultiScale(mini)\n",
    "\n",
    "            face_i = predictions[0]\n",
    "            (x, y, w, h) = [v * size for v in face_i]\n",
    "            face = gray[y:y + h, x:x + w]\n",
    "            face_resize = cv2.resize(face, (im_width, im_height))\n",
    "            face_vector = face_resize.flatten()  # Convertir la imagen en un vector\n",
    "            \n",
    "            # Format response\n",
    "            return InferenceResponse(\n",
    "                model_name=self.name,\n",
    "                model_version=self._settings.parameters.version,\n",
    "                outputs=[\n",
    "                    ResponseOutput(\n",
    "                        name=\"detections\",\n",
    "                        shape=[len(predictions)],\n",
    "                        datatype=\"BYTES\",\n",
    "                        data=[json.dumps(pred) for pred in predictions],\n",
    "                    )\n",
    "                ],\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise InferenceError(f\"Error during inference: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
